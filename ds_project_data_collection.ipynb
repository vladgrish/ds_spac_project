{"cells":[{"cell_type":"markdown","source":["# init env, install packages, import libs..."],"metadata":{"id":"Zw-tL_RhoIcI"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27591,"status":"ok","timestamp":1654937909083,"user":{"displayName":"Vladislav Grischinsky","userId":"00320444372069406027"},"user_tz":-180},"id":"OPD8-4yCs2lc","outputId":"f2ba256b-5bab-4123-8a52-95a0b4fce18f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting yahoo_fin\n","  Downloading yahoo_fin-0.8.9.1-py3-none-any.whl (10 kB)\n","Collecting feedparser\n","  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (2.23.0)\n","Collecting requests-html\n","  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (1.3.5)\n","Collecting sgmllib3k\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->yahoo_fin) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (3.0.4)\n","Collecting parse\n","  Downloading parse-1.19.0.tar.gz (30 kB)\n","Collecting fake-useragent\n","  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n","Collecting pyppeteer>=0.0.14\n","  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.0.1)\n","Collecting pyquery\n","  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n","Collecting w3lib\n","  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.11.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.64.0)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 45.0 MB/s \n","\u001b[?25hCollecting websockets<11.0,>=10.0\n","  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 43.0 MB/s \n","\u001b[?25hCollecting pyee<9.0.0,>=8.1.0\n","  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo_fin) (4.6.3)\n","Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (4.2.6)\n","Collecting cssselect>0.7.9\n","  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n","Building wheels for collected packages: fake-useragent, parse, sgmllib3k\n","  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=321af88a462f419f58835a693ac9d2d668e4195949f9284991f6a7436142317f\n","  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n","  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=a8c1caf2dbb0b0aa7eff6d9580307132ee69a9077d7feed5becafdfb10a95985\n","  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=85767b5a07d142801d299a7602530e1f0e0f6e00e87da50e40b971343576a66f\n","  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n","Successfully built fake-useragent parse sgmllib3k\n","Installing collected packages: websockets, urllib3, pyee, cssselect, w3lib, sgmllib3k, pyquery, pyppeteer, parse, fake-useragent, requests-html, feedparser, yahoo-fin\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 feedparser-6.0.10 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 sgmllib3k-1.0.0 urllib3-1.25.11 w3lib-1.22.0 websockets-10.3 yahoo-fin-0.8.9.1\n"]}],"source":["%matplotlib inline\n","!pip install plotly\n","!pip install yahoo_fin\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns # !\n","import matplotlib.pyplot as plt # !\n","from matplotlib.colors import ListedColormap\n","from mpl_toolkits.mplot3d import Axes3D\n","from IPython.display import HTML\n","import plotly.express as px\n","from yahoo_fin.stock_info import get_data\n","from google.colab import drive\n","import requests\n","from datetime import datetime, date, timedelta\n","\n","mergers = pd.read_csv('https://raw.githubusercontent.com/vladgrish/ds_spac_project/gh-pages/merger_spacs.csv')\n","pending_mergers =  pd.read_csv('https://raw.githubusercontent.com/vladgrish/ds_spac_project/gh-pages/pending_spac_mergers.csv')\n","\n","# some additional settings for sns\n","sns.set()\n","sns.set(rc={\"figure.figsize\": (20, 10)})\n","PALETTE = sns.color_palette('deep', n_colors=3) # will be used for cmap which is a parameter of seaborn scatter\n","CMAP = ListedColormap(PALETTE.as_hex()) # A Colormap instance or registered colormap name. cmap is only used if c is an array of floats.\n","RANDOM_STATE = 42"]},{"cell_type":"markdown","source":["# create dict of merged SPAC companies and their merge date"],"metadata":{"id":"n5-_9sFIoXOH"}},{"cell_type":"code","source":["completed_mergers = {x['Symbol']: datetime.strptime(x['SPAC merger completion date'], '%m/%d/%Y').date() for x in mergers[~mergers['SPAC merger completion date'].isna()].to_dict(orient='records')}"],"metadata":{"id":"NquCtJnfvNtd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get all ticker changes from nasdaq\n","\n","headers = {\n","    'authority': 'api.nasdaq.com',\n","    'accept': 'application/json, text/plain, */*',\n","    'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8,ru;q=0.7',\n","    'origin': 'https://www.nasdaq.com',\n","    'referer': 'https://www.nasdaq.com/',\n","    'sec-ch-ua': '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"101\", \"Google Chrome\";v=\"101\"',\n","    'sec-ch-ua-mobile': '?0',\n","    'sec-ch-ua-platform': '\"Linux\"',\n","    'sec-fetch-dest': 'empty',\n","    'sec-fetch-mode': 'cors',\n","    'sec-fetch-site': 'same-site',\n","    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.41 Safari/537.36',\n","}\n","\n","response = requests.get('https://api.nasdaq.com/api/quote/list-type-extended/symbolchangehistory', headers=headers)\n","symbol_changes = pd.DataFrame([(x['oldSymbol'], x['newSymbol']) for x in response.json()['data']['symbolChangeHistoryTable']['rows']], columns=['old_ticker', 'new_ticker'])"],"metadata":{"id":"8Nzy2ktheSTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654638071646,"user":{"displayName":"Vladislav Grischinsky","userId":"00320444372069406027"},"user_tz":-180},"id":"ZmRQyjnL7wKO","outputId":"f4685339-a38e-4e3e-b2a1-341a7988015a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["33"]},"metadata":{},"execution_count":4}],"source":["# mergers that changed symbols like: {new: old,}\n","\n","changed_symbols = {x['new_ticker']: x['old_ticker'] for x in symbol_changes[symbol_changes['new_ticker'].isin(mergers['Symbol'])].to_dict('records')}\n","len(changed_symbols.keys())"]},{"cell_type":"markdown","source":["# read data from yahoo with yahoo finance api"],"metadata":{"id":"1s2cKTE-owAm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQjTZHn3lnAR"},"outputs":[],"source":["if 'dfs' not in globals():\n","  dfs = {}\n","merged_symbols = mergers['Symbol'].values.tolist()\n","pending_mergers_symbols = pending_mergers['Symbol'].values.tolist()\n","for x in merged_symbols+pending_mergers_symbols:\n","  dfs[x] = get_data(x, start_date=\"01/01/2008\", index_as_date=True, interval='1d')"]},{"cell_type":"markdown","source":["# adding additional features based on ratios within self and ratio to NASDAQ index"],"metadata":{"id":"YerlVhnenxDn"}},{"cell_type":"code","source":["# Adding additional metrics with explanations\n","min_date = date.today()\n","for x in dfs:\n","  min_date = min(dfs[x].index.min(), pd.Timestamp(min_date))\n","nasdaq_df = get_data('^IXIC', start_date=min_date-timedelta(days=1), index_as_date=True, interval='1d')\n","nasdaq_df['nasdaq_pct_change'] = nasdaq_df.close.pct_change()\n","for x in dfs:#[:1]:\n","  # add pct_change column and join it onto another df\n","  dfs[x] = dfs[x].join(nasdaq_df[['nasdaq_pct_change']]) # % change in NASDAQ index\n","  dfs[x]['low/high'] = dfs[x]['low'] / dfs[x]['high'] # low to high ratio\n","  dfs[x]['daily_pct_change'] = 1 - (dfs[x]['open'] / dfs[x]['close']) + 0.00001 # inter day price change (non-zero for devision)\n","  dfs[x]['close_pct_change'] = dfs[x].close.pct_change() # % change in closing price\n","  dfs[x]['pre_market_pct_change'] = dfs[x]['close_pct_change']-dfs[x]['daily_pct_change'] # difference between close % change and inter day change\n","  dfs[x]['nasdaq/stock_pct_change'] = dfs[x]['nasdaq_pct_change'] / dfs[x]['daily_pct_change'] # ration between NASDAQ and stock chnges"],"metadata":{"id":"OQ0drhmdHo8e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# saving all to gdrive (later will upload to github) "],"metadata":{"id":"stCxjX6Mo-_q"}},{"cell_type":"code","source":["for x in dfs:\n","  dfs[x].to_csv(f'/content/drive/MyDrive/ds_project/stock_csv_data/{x}.csv')"],"metadata":{"id":"NdMBGR0nT98T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # removing additional columns in all datasets\n","# for x in dfs:\n","#   dfs[x] = dfs[x][dfs[x].columns[:7]]"],"metadata":{"id":"j9bykL8Tl7os"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# creating some graphs"],"metadata":{"id":"ON5_xEQ5pHVH"}},{"cell_type":"code","source":["#####################\n","### plotly graphs ###\n","#####################\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","def get_stock_plot(x='EVEX'):\n","  fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n","  # fig = px.line(dfs[x], x=dfs[x].index, y=['close'], title=x)\n","  fig.add_trace(go.Scatter(x=dfs[x].index, y=dfs[x]['close'], name=\"close\"), secondary_y=False)\n","  fig.add_trace(go.Scatter(x=dfs[x].index, y=dfs[x]['volume'], name=\"volume\"), secondary_y=True)\n","  fig.update_yaxes(range = [0, max(dfs[x].close.max()+5, 100)], secondary_y=False)\n","  if x in completed_mergers:\n","    fig.add_vline(x=completed_mergers['PIII'], line_dash=\"dash\", line_color=\"green\")\n","  return fig\n","\n","for x in merged_symbols:\n","  # display(HTML(get_stock_plot(x).to_html()))\n","  with open(f'/content/drive/MyDrive/ds_project/merged_spac_html/{x}.html', 'w') as f:\n","    f.write(get_stock_plot(x).to_html(full_html=True, include_plotlyjs='cdn'))\n","#   # ax = sns.lineplot(data=dfs[x], x=dfs[x].index, y='close')\n","#   # plt.title(x)\n","#   # plt.show()"],"metadata":{"id":"Z5vvKYnPln75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# README.md content formating"],"metadata":{"id":"dRA1I3EDpLMF"}},{"cell_type":"code","source":["# this was used to create the MD section of the readme for the gh-pages branch to serve in githab.io\n","merged_symbols.sort()\n","for x in merged_symbols:\n","  if x in completed_mergers:\n","    print(f'[{x} completed @ {completed_mergers[x]}](merged_spac_html/{x}.html)\\n')\n","  else:\n","    print(f'[{x}](merged_spac_html/{x}.html)\\n')"],"metadata":{"id":"elfn4r5I5jR_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# getting the ready data example"],"metadata":{"id":"EEDNxrgWpo8o"}},{"cell_type":"code","source":["# reading all datasets with additional metrics from github (1 minute comparing to 8 when using yahoo api, gdrive is no better...)\n","# this is the final section for getting the data\n","def get_symbol_data(ticker):\n","  return pd.read_csv(f'https://raw.githubusercontent.com/vladgrish/ds_spac_project/gh-pages/stock_csv_data/{ticker}.csv', index_col=0)[1:]\n","\n","if 'datasets' not in globals():\n","  datasets = {}\n","\n","merged_symbols = mergers['Symbol'].values.tolist()\n","pending_mergers_symbols = pending_mergers['Symbol'].values.tolist()\n","\n","for x in merged_symbols+pending_mergers_symbols:\n","  datasets[x] = get_symbol_data(x)"],"metadata":{"id":"1GDgqWE2DW1Q"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"ds_project_data_collection.ipynb","provenance":[],"collapsed_sections":["YerlVhnenxDn","stCxjX6Mo-_q","ON5_xEQ5pHVH","dRA1I3EDpLMF"],"toc_visible":true,"mount_file_id":"1NsWs6it5sDZ6MBEDA-HKk3uuaoZ8vw0E","authorship_tag":"ABX9TyOrqQE8vCTdVvqsT1ZSKY4e"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}